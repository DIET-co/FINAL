{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d14c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "# Load the CNN model\n",
    "model_path = r'C:\\Users\\chand\\Desktop\\New folder\\MMDS\\CNN_POWERFUL.h5'\n",
    "cnn_model = load_model(model_path)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "# You should fit the tokenizer on the entire dataset during training\n",
    "# For demonstration purposes, I'm loading a saved tokenizer. Make sure it's the same tokenizer used during training.\n",
    "tokenizer_path = r'C:/Users/chand/Desktop/New folder/MMDS/tokenizer.pkl'  # Path to your saved tokenizer\n",
    "with open(tokenizer_path, 'rb') as tokenizer_file:\n",
    "    tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "def classify_tweet():\n",
    "    tweet = entry.get()\n",
    "    if not tweet:\n",
    "        result_label.config(text=\"Please enter a tweet.\")\n",
    "        return\n",
    "\n",
    "    # Tokenize and pad the input tweet\n",
    "    sequence = tokenizer.texts_to_sequences([tweet])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=50, padding='post', truncating='post')\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = cnn_model.predict(padded_sequence)[0, 0]\n",
    "\n",
    "    # Display the result\n",
    "    result = \"Good Tweet\" if prediction > 0.6 else \"Bad Tweet\"\n",
    "    result_label.config(text=result)\n",
    "\n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Tweet Classifier\")\n",
    "\n",
    "# Create UI elements\n",
    "frame = ttk.Frame(window, padding=\"10\")\n",
    "frame.grid(column=0, row=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "\n",
    "label = ttk.Label(frame, text=\"Enter Tweet:\")\n",
    "label.grid(column=0, row=0, sticky=tk.W)\n",
    "\n",
    "entry = ttk.Entry(frame, width=50)\n",
    "entry.grid(column=1, row=0, sticky=(tk.W, tk.E))\n",
    "\n",
    "classify_button = ttk.Button(frame, text=\"Classify\", command=classify_tweet)\n",
    "classify_button.grid(column=2, row=0, sticky=tk.W)\n",
    "\n",
    "result_label = ttk.Label(frame, text=\"\")\n",
    "result_label.grid(column=0, row=1, columnspan=3, sticky=tk.W)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1e7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'tokenizer' is the tokenizer object used during training\n",
    "with open('C:/Users/chand/Desktop/New folder/MMDS/tokenizer.pkl', 'wb') as tokenizer_file:\n",
    "    pickle.dump(tokenizer, tokenizer_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
